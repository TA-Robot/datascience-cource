# 1.1.4 期待値・モーメント・共分散

---

本章では、**「確率変数の数値的な特徴」** を把握するための概念として、**期待値 (Mean)**、**モーメント (Moments)**、**分散 (Variance)**、**共分散 (Covariance)**、そしてそれらに関連する生成関数や不等式などを体系的に整理します。  
これらは「確率変数がどのように散らばり、どのような傾向で変動するか」を数量的に記述する道具であり、統計学や確率論の上級トピック（大数の法則、中心極限定理、回帰分析など）へと進む際の重要な基盤です。

---

## 1. 期待値

### 1.1 期待値の直観的意味

確率変数 $X$ が「平均的にどのくらいの値をとるか」を表す指標として、**期待値** が定義されます。これは日常語の「期待」とはやや異なり、「同じ試行を何度も繰り返したときに、その観測値の平均が収束すると期待される値」と捉えるのが正確です。  
離散型でも連続型でも、この考え方は共通しており、測度論的には「$\Omega$ 上の $X(\omega)$ を確率測度 $P$ にしたがって積分する」ことに相当します。離散的な例（サイコロ、コイン投げなど）の場合は「確率 $\times$ 値の総和」として理解しやすいです。

### 1.2 離散型確率変数の定義

確率変数 $X$ が離散型（値を取りうる集合が高々可算）で、その値を $\{x_i\}_{i=1}^\infty$ とし、各 $x_i$ に対応する確率を $P(X=x_i)$ とします。  
このとき、**期待値** $E[X]$ は
$$
E[X]
=
\sum_{i} x_i \, P(X = x_i)
$$
で定義されます。ただし、  
$$
\sum_{i} |x_i|\;P(X=x_i) < \infty
$$
が必要です。これを満たさない場合、期待値は無限大になったり定義できなかったりします。

#### 離散型期待値の存在条件

- 値が高々可算で、それぞれに確率 $p_i = P(X=x_i)$ が定義されていること  
- $\sum_i |x_i|\,p_i < \infty$ であること  

これにより、一般には **絶対収束** が期待値の厳密な存在条件になります。よく用いられるポアソン分布や二項分布などでは、この条件が容易に満たされます。

### 1.3 連続型確率変数の定義

確率変数 $X$ が連続型で確率密度関数 (PDF) $f_X(x)$ をもつとき、期待値は

$$
E[X]
=
\int_{-\infty}^{\infty} x\, f_X(x)\,\mathrm{d}x
$$

で与えられます（ただし積分が絶対収束することが条件です）。  
$$
\int_{-\infty}^{\infty} |x|\,f_X(x)\,\mathrm{d}x < \infty
$$
であれば、期待値は有限値として定まります。代表例として、正規分布 $N(\mu,\sigma^2)$ では $E[X]=\mu$、一様分布 $U(a,b)$ では $E[X]=(a+b)/2$ などが挙げられます。

### 1.4 期待値の基本性質

1. **線形性**  
   期待値が存在する確率変数 $X, Y$ と実数定数 $a, b$ に対して、  
   $$
   E[aX + bY] = a\,E[X] + b\,E[Y]
   $$
   が成り立ちます。これは期待値の最も重要な性質であり、多くの証明や計算で頻繁に用いられます。

2. **単調性**  
   通常、確率変数 $X \le Y$ (ほぼ確実に) ならば $E[X] \le E[Y]$ が成り立ちます。  
   ただし細かい測度論上の注意を除けば、「常に大きいほうの確率変数が平均も大きい」という直感的な性質です。

3. **和の期待値**  
   $E[X + Y] = E[X] + E[Y]$ は、独立・従属にかかわらず常に成り立ちます。これは線形性の特別な場合とみなせます。

4. **非負性と Markovの不等式**  
   $X\ge 0$ の場合は $E[X]\ge 0$ です。さらに、$X$ が大きな値をとる確率を期待値から評価する方法として Markovの不等式があります（後述）。

---

## 2. 分散と標準偏差

### 2.1 分散の定義

期待値（平均）だけでは「ばらつきの程度」を把握しきれない場合が多いため、**分散 (Variance)** が導入されます。  
分散は、「平均からのずれを二乗して平均をとったもの」として

$$
\mathrm{Var}(X)
=
E\bigl[(X - E[X])^2\bigr]
$$

で定義されます。  
$\mathrm{Var}(X)$ は必ず 0 以上であり、もし $\mathrm{Var}(X)=0$ なら、ほぼ確実に $X$ は定数です。

### 2.2 分散の展開公式

分散はしばしば直接の定義よりも、次の公式で計算するほうが簡単です。

$$
\mathrm{Var}(X)
=
E[X^2] \;-\; (E[X])^2.
$$

はじめに $E[X^2]$ を求め、そこから $(E[X])^2$ を引くだけで済むため、具体的な計算が容易になります。  
たとえば正規分布 $N(\mu,\sigma^2)$ では $\mathrm{Var}(X)=\sigma^2$、二項分布 $\mathrm{Binomial}(n,p)$ では $\mathrm{Var}(X)=np(1-p)$ などがこの公式から導かれます。

### 2.3 標準偏差

**標準偏差 (Standard Deviation)** は、分散の平方根

$$
\sqrt{\mathrm{Var}(X)}
$$

として定義されます。分散は元の単位の二乗になるため、標準偏差を使うことで元の単位に整合した指標を得られます。  
たとえば「テストの平均点が 60 点、標準偏差が 10 点である」というように示すと、ばらつきの大きさを直観的に把握しやすくなります。

### 2.4 分散のその他の性質

1. **分散の線形性は限定的**  
   $\mathrm{Var}(aX + bY)=a^2\,\mathrm{Var}(X) + b^2\,\mathrm{Var}(Y) + 2ab\,\mathrm{Cov}(X,Y)$ という形になり、共分散の項が入ります。$X, Y$ が独立であれば $\mathrm{Cov}(X,Y)=0$ なので $\mathrm{Var}(X+Y)=\mathrm{Var}(X)+\mathrm{Var}(Y)$ となります。

2. **分散の存在条件**  
   $\mathrm{Var}(X)$ が有限であるには、$E[X^2]$ が有限である必要があります（$\int x^2 f_X(x) \,\mathrm{d}x < \infty$ など）。コーシー分布のように分散が存在しない分布もあります。

---

## 3. 共分散と相関係数

### 3.1 共分散の定義

2つの確率変数 $X, Y$ の「同時変動」を測る量として、**共分散 (Covariance)** が定義されます。

$$
\mathrm{Cov}(X, Y)
=
E\bigl[(X - E[X])(Y - E[Y])\bigr].
$$

あるいは

$$
\mathrm{Cov}(X, Y)
=
E[XY] \;-\; E[X]\,E[Y]
$$

と書くことも多いです。

#### 正・負・ゼロ

- $\mathrm{Cov}(X, Y) > 0$: $X$ が大きいとき、$Y$ も大きい方向へ動きやすい  
- $\mathrm{Cov}(X, Y) < 0$: $X$ が大きいとき、$Y$ は小さいほうへ動きやすい  
- $\mathrm{Cov}(X, Y) = 0$: 線形的には無相関だが、独立を意味するわけではありません（後述）。

### 3.2 相関係数

共分散をさらに規格化し、$-1$ から $+1$ の間に収めた指標が **相関係数 (Correlation Coefficient)** です。

$$
\rho(X,Y)
=
\frac{\mathrm{Cov}(X,Y)}{\sqrt{\mathrm{Var}(X)\,\mathrm{Var}(Y)}}.
$$

- $|\rho|=1$ に近いほど、ほぼ完全な線形関係  
- $\rho=0$ は線形相関がないことを意味しますが、独立とは限りません

### 3.3 共分散・相関係数の性質

1. **双線形性**  
   $\mathrm{Cov}(aX + bY,\,Z)=a\,\mathrm{Cov}(X,Z)+ b\,\mathrm{Cov}(Y,Z)$ など、共分散は線形演算に対応してくれます。

2. **独立性との関係**  
   $X$ と $Y$ が独立であれば $\mathrm{Cov}(X,Y)=0$ となりますが、その逆は真ではありません。共分散が 0（無相関）であっても、非線形な依存関係が存在する可能性があります。  
   ただし正規分布の範囲では「無相関なら独立」が成り立つという特別な性質があります。

---

## 4. 高次モーメントと中心モーメント

### 4.1 $k$ 次モーメント

確率変数 $X$ の **$k$ 次モーメント** は $E[X^k]$ で表されます。すでに $k=1$ が期待値、$k=2$ が分散の一部に関連する値でした。一般的には

$$
\mu'_k
=
E[X^k]
\quad (k=1,2,3,\dots)
$$

と呼ばれ、これを **生モーメント (Raw Moment)** といいます。

### 4.2 中心モーメント

**中心モーメント (Central Moment)** は、$(X-E[X])$ によるずれを用いたモーメントで、

$$
\mu_k
=
E\bigl[(X - E[X])^k\bigr].
$$

- $\mu_2 = \mathrm{Var}(X)$  
- $\mu_3$ は分布の非対称性に対応し、歪度の計算に用いられます  
- $\mu_4$ は分布の裾の重さやピークの形状を測る尖度と関連します

### 4.3 歪度 (Skewness) と尖度 (Kurtosis)

- **歪度 (Skewness)**  
  $$
  \text{Skewness}(X)
  = \frac{\mu_3}{(\mu_2)^{3/2}}
  = \frac{E\bigl[(X-\mu)^3\bigr]}{\sigma^3}.
  $$
  正なら右裾が長い分布、負なら左裾が長い分布を示唆します。

- **尖度 (Kurtosis)**  
  $$
  \text{Kurtosis}(X)
  = \frac{\mu_4}{(\mu_2)^2}
  = \frac{E\bigl[(X-\mu)^4\bigr]}{\sigma^4}.
  $$
  数値が大きいほど、裾が重い（あるいはピークが尖っている）分布といえます。正規分布では 3 です（統計学では Excess Kurtosis = Kurtosis - 3 を使うことも多いです）。

---

## 5. モーメント母関数 (MGF) と累積量生成関数 (CGF)

### 5.1 MGF (Moment Generating Function) の定義

確率変数 $X$ の **モーメント母関数 (MGF)** は

$$
M_X(t)
=
E\bigl[e^{tX}\bigr]
$$

が有限となる範囲（ふつうは $t=0$ 近傍）で定義されます。  
この $M_X(t)$ をテイラー展開すると、

$$
M_X(t)
=
\sum_{k=0}^{\infty} \frac{E[X^k]}{k!}\,t^k,
$$

となり、すべてのモーメント $E[X^k]$ を一括で扱えます。  
ただし、コーシー分布のように $E[e^{tX}]$ が無限大になり、MGF が存在しない場合もあります。

### 5.2 CGF (Cumulant Generating Function)

**累積量生成関数 (CGF)** は

$$
K_X(t)
=
\log M_X(t)
$$

と定義され、微分係数として **キュムラント (Cumulant)** を得られます。たとえば  
$$
K'_X(0)=E[X],\quad K''_X(0)=\mathrm{Var}(X),
$$
など、高次微分を通じて歪度や尖度にも関連する量が得られます。中心極限定理や大数の法則の証明では、この CGF（あるいは特性関数）を用いることが多いです。

### 5.3 MGF と特性関数

MGF と並んで有名なものに **特性関数** があり、これは

$$
\phi_X(t)
=
E\bigl[e^{\,i\,t\,X}\bigr]
$$

で定義されます（$i$ は虚数単位）。特性関数は絶対値が常に 1 なので常に収束し、どんな確率変数に対しても存在する点が大きなメリットです。一方、実指数を使う MGF は収束しない場合もありますが、モーメントの導出には直接的です。  
本章では主にモーメント周りの話題に集中するため、特性関数の詳細には触れません。

---

## 6. 条件付き期待値と独立性

### 6.1 条件付き期待値の定義

確率変数 $X, Y$ があり、$Y$ のとる値 $y$ がわかったときに $X$ がどのくらいの平均値をもつかを表すのが **条件付き期待値 $E[X\mid Y=y]$** です。  
離散型なら  
$$
E[X \mid Y=y]
=
\sum_{x} x \; P(X=x \mid Y=y),
$$
連続型なら  
$$
E[X \mid Y=y]
=
\int x \; f_{X\mid Y}(x\mid y) \,\mathrm{d}x,
$$
などと書けます。実際には測度論上の微妙な扱いがありますが、概念的には「$Y=y$ という情報が与えられたときの $X$ の平均」です。

### 6.2 条件付き期待値の性質

- **線形性**  
  $E[aX + bY \mid Z=z] = a\,E[X\mid Z=z] + b\,E[Y\mid Z=z]$。  
- **全期待値の法則 (Law of Total Expectation)**  
  $$
  E[X] = E\bigl[E[X\mid Y]\bigr].
  $$
  これは期待値を分割して合算する際によく用いられます。  
- **独立性との関係**  
  $X$ と $Y$ が独立であれば、$E[X\mid Y=y] = E[X]$ となります。つまり、$Y$ の値を知っても $X$ の期待値に影響はありません。

### 6.3 反復期待値の法則の応用例

「サイコロの出目 $Y$ に応じてコイン投げを $Y$ 回行い、その表の合計数を $X$ とする」などの問題で、$E[X]$ を効率的に求めることができます。  
統計的推測やデータサイエンスでも「部分集団ごとの平均を合算して全体の平均を出す」といったアイデアは広く使われています。

---

## 7. Markovの不等式・Chebyshevの不等式

ここでは、大きな値（あるいは平均から大きく離れた値）をとる確率を、分布の詳細を使わずに**期待値や分散を介して**上から押さえる手法として、**Markovの不等式** と **Chebyshevの不等式** を詳しく解説します。これらは、大数の法則や中心極限定理の証明の導入部でもよく使われる基本的な不等式です。どちらも実際の確率より緩い評価しか与えないことがありますが、それでも「分布形状を知らなくても適用できる」という普遍性を持つため、多くの場面で役立ちます。

---

### 7.1 Markovの不等式 — 非負変数への適用

#### 7.1.1 定義と直感

確率変数 $X \ge 0$（非負）に対して、ある正の数 $a>0$ を設定するとき、Markovの不等式は

$$
P(X \ge a) \;\le\; \frac{E[X]}{\,a\,}
$$

と表されます。  
これは「期待値だけが分かっていれば、とりあえず $X$ が $a$ 以上になる確率を上から押さえられる」という便利な式です。非負であるという条件は重要で、$X$ が負の値をとる可能性があると不等式は成立しません。

#### 7.1.2 簡単な証明

証明は次のようにシンプルです。$X \ge 0$ なので、$X \mathbf{1}_{\{X\ge a\}} \ge a \mathbf{1}_{\{X\ge a\}}$ が成り立ちます（ここで $\mathbf{1}_{\{X\ge a\}}$ は「$X \ge a$ であることを示す指示関数」）。  
期待値をとると、

$$
E\bigl[X \mathbf{1}_{\{X\ge a\}}\bigr]
\;\ge\;
E\bigl[a\,\mathbf{1}_{\{X\ge a\}}\bigr]
=
a \, P(X \ge a).
$$

一方で、左辺は $X \mathbf{1}_{\{X\ge a\}} \le X$ から

$$
E\bigl[X \mathbf{1}_{\{X\ge a\}}\bigr]
\;\le\;
E[X].
$$

以上をまとめると

$$
a \, P(X \ge a)
\;\le\;
E[X],
$$

すなわち

$$
P(X \ge a)
\;\le\;
\frac{E[X]}{\,a\,}
$$

が得られます。

#### 7.1.3 使用例と限界

- **使用例**: 大数の法則や中心極限定理の導入で、$(X-\mu)^2$ のような非負変数を扱う際に応用したり、期待値から「極端に大きな値をとる確率がどれくらいか」を評価する際に利用します。  
- **限界**: 実際の確率分布によっては、$P(X \ge a)$ が非常に小さいにもかかわらず、$\frac{E[X]}{a}$ は大きめの値を示すことが多々あります。つまり、**緩い評価** しか与えられない場合がある点には留意が必要です。

---

### 7.2 Chebyshevの不等式 — 平均からのズレへの適用

#### 7.2.1 定義と意味

Chebyshevの不等式は、**平均 $\mu = E[X]$** と **分散 $\sigma^2 = \mathrm{Var}(X)$** をもつ確率変数 $X$ に対し、

$$
P\bigl(|X - \mu| \;\ge\; \alpha \bigr)
\;\le\;
\frac{\sigma^2}{\,\alpha^2\,}
$$

と表される不等式です。特に $\alpha = k \sigma$ とすると、

$$
P\bigl(|X - \mu| \;\ge\; k \,\sigma \bigr)
\;\le\;
\frac{1}{\,k^2\,}.
$$

これは「確率変数が平均から $k$ 倍の標準偏差以上に外れる確率」を上から押さえる式になっています。

#### 7.2.2 Markovの不等式との関係

Chebyshevの不等式は、Markovの不等式を変形して導くことができます。具体的には、

$$
P\bigl(|X-\mu| \ge \alpha\bigr)
=
P\!\Bigl((X-\mu)^2 \ge \alpha^2\Bigr).
$$

ここで $Y = (X-\mu)^2$ は非負の確率変数なので Markovの不等式を適用すると、

$$
P\bigl(Y \ge \alpha^2\bigr)
\;\le\;
\frac{E[Y]}{\alpha^2}
=
\frac{\mathrm{Var}(X)}{\alpha^2}
=
\frac{\sigma^2}{\alpha^2}.
$$

よって

$$
P\bigl(|X-\mu|\ge \alpha\bigr)
\;\le\;
\frac{\sigma^2}{\alpha^2}.
$$

#### 7.2.3 応用と有用性

- **大数の法則（弱法則）の証明**: $\displaystyle P\!\bigl(\bigl|\overline{X}_n - \mu\bigr| \ge \varepsilon\bigr)$ を上から押さえるのに使うなど、大数の法則の証明において出発点になります。  
- **安定性の評価**: 「分散 $\sigma^2$ がわかっていれば、平均から $\alpha$ 以上ずれる確率は $\sigma^2 / \alpha^2$ 以下だ」という汎用性の高い評価が得られます。  
- **限界**: Chebyshevの不等式も Markov同様に、実際の分布から見ると緩い評価しか与えない場合があります。特に正規分布であれば、より精密な評価（例えば $3\sigma$ ルール）が可能です。しかし分布の形に依存せず適用できる点が魅力です。

#### 7.2.4 例: $k = 2$ の場合

$k=2$ の場合、

$$
P\bigl(|X - \mu|\ge 2\,\sigma\bigr) \;\le\; \frac{1}{4}.
$$

実際の正規分布では、$|X-\mu|\ge 2\,\sigma$ に入る確率は約 4.55% ですが、Chebyshevの不等式だと 25% という上限を与えるので、やはりだいぶ緩めです。  
それでも、全く分布の具体形状を知らない状況下で「25%を超えない」という情報が得られることには一定の価値があります。

---

### 7.3 総合コメント

- **Markovの不等式** は「非負確率変数 $X\ge 0$ に対して $P(X\ge a) \le \frac{E[X]}{a}$」というシンプルな形。  
- **Chebyshevの不等式** は「平均と分散がわかるなら、平均から外れる確率を分散で評価できる」という形。  
- いずれも「具体的な分布形状が未知な場合」に強力です。  
- 実際の分布によっては過大評価になる場合が少なくありませんが、理論的な証明や上界評価の枠組みとして、確率論・統計学のあらゆる領域で活躍しています。  

---

## 8. 期待値・分散の補足事項

ここでは、**期待値や分散、その周辺の指標** について追加的なトピックを解説します。特に、モーメントを用いた分布の収束や、分散以外のばらつき指標、そして「そもそも期待値・分散が存在しない」分布の例などは、確率論の理解を深めるうえでとても重要です。

---

### 8.1 モーメントと分布収束

#### 8.1.1 モーメント収束と確率収束

確率論には、確率変数の列 $X_n$ が別の確率変数 $X$ に「収束」するという概念がいくつかあります。代表的なものは以下の通りです。

- **確率収束**: $P(|X_n - X|\ge \epsilon) \to 0$ となる  
- **ほぼ確実収束**: $P(\lim_{n\to\infty} X_n = X) = 1$  
- **$L^p$ 収束**: $E[|X_n - X|^p]\to 0$  
- **モーメント収束**: $E[|X_n|^k]\to E[|X|^k]$ のように、モーメントが収束

これらは相互に包含関係があり、最も強いのはほぼ確実収束、最も弱いのは分布収束（中心極限定理等で使われる意味での「分布関数の点列収束」）です。

#### 8.1.2 分散と収束の関係

$X_n$ の分散が 0 に収束するとか、$X_n$ の分散が一定値に収束するといった状況は、確率収束や $L^2$ 収束を議論する際に重要です。特に

$$
\mathrm{Var}\!\bigl(\overline{X}_n\bigr) = \frac{\sigma^2}{n}
$$

のような振る舞いは、大数の法則や中心極限定理の基盤になっています。モーメントの有限性（$E[X^2]<\infty$ など）がないと、これらの定理が破綻するケースも多いです。

#### 8.1.3 実務的な視点

機械学習や信号処理などで「最適化アルゴリズムの収束」を確率的に論じる場合など、分散の減少を見て「収束している」と判断することがあります。モーメント論はそうした実務的な収束評価にも生かされています。

---

### 8.2 分散以外のばらつき指標

分散は「二乗平均偏差」としてもっとも一般的ですが、他にもさまざまなばらつき指標があります。

#### 8.2.1 絶対偏差 (Mean Absolute Deviation, MAD)

$$
\mathrm{MAD}(X)
=
E\bigl[\,|X - E[X]|\,\bigr].
$$

- 分散と比べると、「二乗」ではなく「絶対値」で測るので、外れ値（極端に大きい値）の影響をやや抑制します。  
- ロバスト統計学では、この絶対偏差に着目した指標が使われることが多いです。

#### 8.2.2 四分位範囲 (Interquartile Range, IQR)

- 分布の 25% 点 ($Q1$) と 75% 点 ($Q3$) の差として  
  $$
  \mathrm{IQR}(X) = Q3 - Q1.
  $$
- 箱ひげ図（Box-Plot）で可視化される指標で、「データの中間 50% がどれほどの幅に収まっているか」を示します。  
- 分布の形が非対称でも、四分位範囲はそれに左右されにくいという利点があります。

#### 8.2.3 一般の $L^p$ ノルム

より一般的に

$$
\bigl(E[|\,X-\mu\,|^p]\bigr)^{1/p}
$$

を考えることができます。$p=2$ の場合が分散を用いた標準偏差、$p=1$ が絶対偏差などに相当します。これらを総称して「$L^p$ ノルム」と呼ぶ場合もあり、データの形に合わせて $p$ を選ぶことで外れ値へのロバスト性を調整できる利点があります。

---

### 8.3 期待値・分散が存在しない分布

#### 8.3.1 コーシー分布

コーシー分布は、**平均も分散も定義できない代表例** です。具体的な確率密度関数は

$$
f_X(x)
=
\frac{1}{\pi}\,
\frac{\gamma}{(x-x_0)^2 + \gamma^2}
$$

の形（位置パラメータ $x_0$、スケールパラメータ $\gamma>0$）で、裾が非常に重いため、

$$
E[|X|] = \infty, \quad E[X^2] = \infty,
$$

となってしまいます。結果として $\mathrm{Var}(X)$ も定義できません。

#### 8.3.2 $\alpha$ ステーブル分布

コーシー分布は「$\alpha$ ステーブル分布」の一種です。$\alpha$ が 1 以上 2 未満のとき、分散が無限大になるケースがあり、$\alpha$ が 1 のときがコーシー分布です。  
このような分布では **中心極限定理** の修正形が必要になるなど、モーメントが存在しないことが確率論に大きな影響を与えます。

#### 8.3.3 分布解析での注意点

- モーメント母関数を使った議論が通じなくなる  
- 分散を指標として用いる統計手法が破綻する  
- 特性関数など、モーメント以外の道具が必須になる

現実の現象でも金融データや地震データなど、一部で非常に重い裾をもつ分布が観測される場合があり、注意が必要です。

---

## 9. まとめ

本章の総仕上げとして、主に以下の視点を改めて強調したいです。「Markovの不等式・Chebyshevの不等式」と「期待値・分散の補足トピック」に焦点を当て、学んだ内容を整理します。

---

### 9.1 Markovの不等式・Chebyshevの不等式の重要性

1. **分布形状に依存しない評価**  
   これらの不等式は「$X$ がどんな分布をしているか」をほとんど仮定せずに、**期待値や分散** だけで「極端な事象」の確率を制約できます。  
2. **大数の法則・中心極限定理の基盤**  
   - 大数の法則（特に弱法則）の証明で、Chebyshevの不等式が欠かせません。  
   - 変数変換 $(X-\mu)^2$ に対する Markovの不等式から Chebyshevを導くという流れも基礎的です。  
3. **緩いが汎用性が高い**  
   実際の確率をきっちり予測するわけではなく、**上界** を与えるだけです。よって過大評価になる場合も少なくありません。しかし、分布をまったく仮定しない場合はこれが最大限の武器ともいえます。

---

### 9.2 期待値・分散をめぐる補足事項

1. **モーメント収束と収束概念**  
   - 確率論には複数の収束概念があり、モーメントの有限性・収束性が理論を支える重要な役割を果たします。  
   - 分散が有限であるかどうかは、大数の法則・中心極限定理の適用可否を左右します。  

2. **分散以外のばらつき指標**  
   - 絶対偏差や四分位範囲など、分散に代わる（あるいは補完する）指標が存在します。  
   - ロバスト統計学では、外れ値に弱い分散ではなく、絶対偏差や四分位範囲を重視することが多いです。  

3. **期待値・分散が存在しない分布**  
   - コーシー分布のように、重い裾をもつために $E[X]$ や $\mathrm{Var}(X)$ が無限大になる例があります。  
   - そのような場合、MGF も収束しないので、**分布解析に特性関数を使う** 必要が生じます。  
   - 現実のデータ（金融や災害など）でそうした分布が現れるケースもあり、実務家も理論的注意を払わなければなりません。

---

### 9.3 本章全体の再整理

- **7章で学んだこと**  
  - **Markovの不等式**: 非負変数への単純な期待値比による上界  
  - **Chebyshevの不等式**: 平均からのずれを分散で評価する不等式  
  - どちらも「分布に関する深い知識がなくても適用できる」「大数の法則の証明で要所となる」など、汎用性が高いです。

- **8章で学んだこと**  
  - **モーメント収束と確率収束**: さまざまな収束概念の概要  
  - **分散以外のばらつき指標** (MAD, IQR, $L^p$ ノルムなど)  
  - **期待値・分散がない分布**: コーシー分布や $\alpha$ ステーブル分布のように、そもそも二乗が積分不可能な場合  
  - これらを通じて「分散や期待値があるのは当たり前ではない」「状況に応じた指標選択が必要」という理解を深めます。

- **本章の総括**  
  - 本章全体を通して「確率変数の中心的指標（期待値）」「ばらつきを示す指標（分散・共分散など）」を体系的に学びました。  
  - さらに「高次モーメント」「モーメント母関数」「条件付き期待値」「Markov/Chebyshevの不等式」などを押さえることで、確率論の重要な定理・手法を支える基盤が固まったといえます。

---

### 9.4 次に進む道筋

1. **大数の法則 (Law of Large Numbers)**  
   - 「たくさんの独立同分布の試行を行えば、その平均が理論値（期待値）に近づく」というものです。Chebyshevの不等式を用いた証明が初歩的な導入になります。  
2. **中心極限定理 (Central Limit Theorem)**  
   - 分散が有限な場合、独立同分布の確率変数の和（あるいは平均）は試行回数が大きくなるほど正規分布に近づきます。MGF や特性関数を使った証明が典型的です。  
3. **統計的推測・回帰分析**  
   - サンプル平均やサンプル分散、不偏推定量などを学ぶ際に、本章の概念（期待値・分散・共分散など）が必須です。特に回帰分析では共分散と相関が理論の土台になります。  
4. **測度論的確率論**  
   - さらに厳密な扱いを求めるなら、ルベーグ積分に基づいた測度論的な定義へと進むことができます。そこでは、本章で扱った概念がすべて測度の言葉で再定式化されます。

---

#### 9.4.1 応用分野での活躍

- **機械学習**  
  - 統計的学習理論の証明で、Markov/Chebyshevの不等式や集中不等式（HoeffdingやBernsteinなど）をバリエーションとして使います。  
  - モーメント母関数があれば、テールの評価（大きな値をとる確率の減衰）を厳密に行えるため、汎化誤差の評価にも役立ちます。

- **金融工学**  
  - 分散 (Variance) と相関 (Correlation) はポートフォリオ理論の中心的な要素であり、リスク管理の枠組みを作る際に欠かせません。  
  - ただし、実際の金融時系列は「重い裾を持つ」ことが多く、コーシー的挙動（分散が効かない）の可能性にも注意が必要です。

- **物理学・自然科学**  
  - 統計物理では「期待値や分散」が熱力学量と対応する場合があり、Chebyshevの不等式は分布の濃厚な尾部の評価にも使われます。  
  - 大数の法則や中心極限定理に基づく近似を多用するため、本章の概念が不可欠です。

---

### 9.5 本章の締めくくり

本章では、期待値・分散・共分散などの基本指標に加え、モーメント母関数、条件付き期待値、そして Markov・Chebyshevの不等式のような基礎的評価手段を取り上げました。  
これらは今後の確率論・統計学の展開において繰り返し使われる概念・道具です。たとえば大数の法則や中心極限定理といった「確率論の花形定理」を理解するにも、期待値と分散、そして不等式の考え方は欠かせません。また、応用分野（機械学習・金融・自然科学など）で確率的モデルを構築する際にも、これらの概念が分析や推測の基礎を支えています。  

ぜひ、ここで学んだ内容をもとに、次のステップとして「確率変数の収束」や「数理統計学の基礎理論」「ベイズ推定」などへ進んでいただきたいです。確率論の醍醐味がさらに深まるはずです。
